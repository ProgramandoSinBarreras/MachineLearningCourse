{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tpCmn_Bv7SYs"},"source":["<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/NonSupervised.png\" alt=\"Drawing\" style=\"width:1700px;\">\n","\n","\n","# <center> 11. Non Supervised Learning: K-Means Algorithm! </center>\n"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"yl1kd9DV7SY4"},"outputs":[],"source":["#@title 1. MONTAR EL DRIVE { display-mode: \"form\" }\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/My Drive/Machine_Learning_Course/')\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"LwoCufEm7SYw"},"outputs":[],"source":["#@title 2. LOAD LIB { display-mode: \"form\" }\n","from sklearn.datasets import *\n","import numpy as np  \n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans \n","from sklearn.cluster import DBSCAN"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BjLygrRZ7SY_"},"source":["## <span style=\"color:red\"> What do you do when your dataset doesn’t have any labels?</span>: \n","\n","Unsupervised learning is when you only have input data $\\mathbf{X}$ and no corresponding output variables $\\mathbf{y}$. The main **goal** for unsupervised learning is **to model the underlying structure** or distribution in the data in order to learn more about the data.\n","\n","\n","- There is no correct answers and **there is no teacher**\n","- The goal is to dicover interesting structure **(patterns)** in the data.\n","- useful for\n","    - Big Data: Take representative samples of a lot of data\n","    - It is necessary focus on understanding customers\n","    - To find patterns in dynamic twitter\n","    - To find playlist music data\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GZo0H1TT7SZB"},"source":["## <span style=\"color:orange\"> 2. student</span>: \n","\n","For instance, how to group these data?. Try with goups of $K=1,2,3,4$\n","\n","<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/Uncluster-student.png\" style=\"width:400px;\">\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Qo9Usu2L7SZD"},"source":["## Clustering and K-means algorithm\n","\n","The idea is to **discover** inherent groups in data and to recover **centroid or representative** samples.\n","    - Groups or clusters are set of data that share **similar** features\n","    - For instance find customer patterns,  such as people that buy X also tend to buy Y\n","\n","\n","**How to cluster automatically?**\n","\n","R:/ The problem is computationally difficult (NP-hard)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lqfilDwD7SZE"},"source":["## K-means  O(n)\n","\n","The KMeans algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares\n","\n","\n","- **clustering your data points into a number (K) of mutually exclusive clusters.**\n","\n","<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/kmeans.gif\" >\n","\n","-**How it works ?**\n","\n","\n","1. Initialize $K$ centroids $C = \\{c_1, c_2, \\ldots c_k\\}$\n","    - The center points are vectors of the same length $c_i \\in \\mathbb{R}^{F}$\n","2. Each data point is classified by computing the distance between that point and each group center\n","    - $\\arg \\min_{c_i \\in C} dist(c_i, x)^{2}$\n","3. Based on these classified points, we recompute the group center by taking the mean of all the vectors in the group.\n","\n","    - $c_i = \\frac{1}{|c_i|}\\sum_{x_i \\in c_i} x_i$\n","\n","4. Repeat these steps for a set number of iterations or until the group centers don’t change much between iterations. \n","\n","\n","**Go to te action ...**\n"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"w8gN2BH67SZG"},"outputs":[],"source":["X, y = make_blobs(n_samples=300, centers=4, n_features=2,random_state=0)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"GDcea5kL7SZM"},"outputs":[],"source":["plt.scatter(X[:,0], X[:,1], c=\"blue\", cmap='rainbow'); "]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"fwPqlCYG7SZU"},"outputs":[],"source":["kmeans = KMeans(n_clusters=3)  \n","kmeans.fit(X)  "]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"lexxIFwb7SZb"},"outputs":[],"source":["#print(kmeans.cluster_centers_)  \n","#print(kmeans.labels_)  \n","plt.scatter(X[:,0],X[:,1], c=kmeans.labels_, cmap='rainbow')  \n","plt.scatter(kmeans.cluster_centers_[:,0] ,kmeans.cluster_centers_[:,1], color='black')  "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FnT1yHnx7SZh"},"source":["however...some of the times the k-means can **fail**"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"XC7wafc07SZi"},"outputs":[],"source":["X,y = make_moons(200, noise=0.05)\n","kmeans = KMeans(n_clusters=2)  \n","kmeans.fit(X)  \n","\n","plt.figure(figsize=(10,4))\n","plt.subplot(121)\n","plt.scatter(X[:,0], X[:,1], c=\"blue\", cmap='rainbow');\n","plt.subplot(122) \n","plt.scatter(X[:,0],X[:,1], c=kmeans.labels_, cmap='rainbow')\n","plt.scatter(kmeans.cluster_centers_[:,0] ,kmeans.cluster_centers_[:,1], color='black')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4sflQaS67SZn"},"source":["### Some Disadvantajes\n","\n","- The K is imposed (some empirical strategies are proposed as elbow (codo) aproach) [5]\n","- the start from random choices yield different cluster results\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B_HllxAj7SZq"},"source":["## DBSCAN  $O(n^2)$\n","### Density-Based Spatial Clustering of Applications with Noise\n","\n","It is a  density-based algorithm, in which **clusters** are set of points with **high density**. A point belongs to a cluster if it is near of neighboorhood grouped points (*del montón*). The DBSCAN find find arbitrarily sized and arbitrarily shaped clusters. DBSCAN is also able to find outlier points and label as noise.\n","\n","\n","<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/DBScan.gif\" >\n","\n","\n","[Visualizing DBSCAN](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)\n","\n","\n","-**How it works ?**\n","1. Define: \n","    - **ε>0 :** distance to be considered a point as part of a neighborhood\n","    - **$c_i \\geq$ minpoints :** number of point minimum to be considered as a cluster. \n","2. Starts with an arbitrary non-viseted point. The neighborhood points are defined as point with a distance less or equal to a ε. Points are labelled as *visited*\n","    - If neighborhood is larger than **minPoints** then the group is a **cluster**\n","    - Otherwise, the point will be labeled as noise (later this noisy point might become the part of the cluster).\n","\n","3. This procedure is repeated for all of the new points that have been just added to the cluster group.\n","\n","4. This process of steps 2 and 3 is repeated until all points within the ε neighborhood of the cluster have been visited and labelled.\n","\n","5. A new unvisited point is retrieved and processed, leading to the discovery of a further cluster or noise. \n","\n","\n","**Go to the action**"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"xPEKT8oR7SZs"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","X,y = make_moons(200, noise=0.05) \n","X = StandardScaler().fit_transform(X) #mean zero and variance one\n","\n","DBS = DBSCAN(eps=.3)\n","DBS.fit(X) \n","\n","plt.figure(figsize=(12,4))\n","plt.subplot(121)\n","plt.scatter(X[:,0], X[:,1], c=\"blue\", cmap='rainbow');\n","plt.subplot(122) \n","plt.scatter(X[:,0],X[:,1], c=DBS.labels_, cmap='rainbow');"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jdgXPW2R7SZy"},"source":["### Some Disadvantajes of DBSCAN\n","\n","- Asumme similar densities on all clusters.\n","- Could exist some limitation to separate clusters."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jtHoeh9V7SZz"},"source":["## shopping trends\n","\n","- Annual Income (in thousands of dollars) \n","- Spending Score (1-100) signifies how often a person spends money in a mall being the highest spender [6]. "]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"af9Cjn2b7SZ1"},"outputs":[],"source":["import pandas as pd  \n","customer_data = pd.read_csv('Data/shopping_data.csv')  \n","print( customer_data.shape  )\n","customer_data.head(3)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"-23rJRtI7SZ7"},"outputs":[],"source":["data = customer_data.iloc[:, 3:5].values  \n","data.shape"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M2Z7LiG_7SaB"},"source":["## <span style=\"color:orange\"> 1. student</span>: \n","\n","- What about use other features for clustering?  \n","- How genre and age are correlated?"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"cGxRx_2S7SaD"},"outputs":[],"source":["\n","kmeans = KMeans(n_clusters=5)  \n","kmeans.fit(data)  \n","\n","DBS = DBSCAN(eps=10)\n","#AgglomerativeClustering(n_clusters=2, linkage= \"ward\")\n","DBS.fit(data) \n","plt.figure(figsize=(15, 5))  \n","plt.subplot(131)\n","plt.scatter(data[:,0], data[:,1], cmap='rainbow') \n","plt.subplot(132)\n","plt.title(\"BDScan\")\n","plt.xlabel(\"Annual income\")\n","plt.ylabel(\"Spending score \")\n","plt.grid(alpha=0.2)\n","plt.scatter(data[:,0], data[:,1], c=DBS.labels_, cmap='rainbow')  \n","plt.subplot(133)\n","plt.scatter(data[:,0], data[:,1], c=kmeans.labels_, cmap='rainbow') \n","plt.xlabel(\"Annual income\")\n","plt.title(\"K-means\")\n","plt.grid(alpha=0.2)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"eN1HOc6y7SaI"},"outputs":[],"source":["# challenge yourself\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oJKEx5kT7SaO"},"source":["## <span style=\"color:orange\"> 2. student</span>: \n","\n","- What about apply cluster an image?  \n","- Try in the next images"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"MO1yUssK7SaQ"},"outputs":[],"source":["from skimage import io\n","fig = plt.figure(figsize=(9,9))\n","img_1 = io.imread(\"Imagenes/jacanamijoy.jpg\")\n","img_2 = io.imread(\"Imagenes/juanCabas.jpg\")\n","\n","\n","plt.figure(figsize=(15,4))\n","plt.subplot(121);\n","plt.imshow(img_1, cmap = plt.cm.Greys_r), plt.grid();\n","plt.subplot(122)\n","plt.imshow(img_2, cmap = plt.cm.Greys_r), plt.grid();"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"xKvYnBqB7SaX"},"outputs":[],"source":["# challenge yourself\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1f_Z5P2f7Sab"},"source":["## <span style=\"color:orange\"> 3. student</span>: \n","\n","- What about normalize data?  \n","- What about introducing (x, y) as features?"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"I12rqS7R7Sac"},"outputs":[],"source":["# challenge yourself\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nkLRQoUq7Sah"},"source":["## Many options with different performances...\n","   ... So, as  **scientific of data**, please select the best in your application! [4]\n","<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/comparison.png\" style=\"width:700px;\">"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7j4v0_aN7Saj"},"source":["<span style=\"font-size:larger;\"> *Yan Lecun, director of AI research, explains that unsupervised learning — teaching machines to learn for themselves without having to be explicitly told if everything they do is right or wrong — is the key to “true” AI.*[3] </span>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"i-mw9sL77Sal"},"source":["## References\n","\n","[1] Scikit-learn for kmeans: http://scikit-learn.org/stable/modules/clustering.html#k-means\n","\n","[2]Introduction to Unsupervised lerning: https://blog.algorithmia.com/introduction-to-unsupervised-learning/\n","\n","[3] Data Science: https://towardsdatascience.com/unsupervised-learning-with-python-173c51dc7f03\n","\n","[4] Sklearn comparison: https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py\n","\n","[5] K-means by hand: https://mubaris.com/posts/kmeans-clustering\n","\n","[6] dataset: https://stackabuse.com/hierarchical-clustering-with-python-and-scikit-learn/\n","\n","\n","---\n","<img src=\"https://github.com/ProgramandoSinBarreras/MachineLearningCourse/blob/main/Imagenes/01_introduccion_python/programando_sin_barreras.jpeg?raw=true\" alt=\"Drawing\" style=\"width:1000px;\">\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"11-Notes-Non-Supervised-Learning.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.14"}},"nbformat":4,"nbformat_minor":0}
